# ComfyUI Arguments for NVIDIA B200 (192GB VRAM)
# These are optimized for datacenter GPU with massive VRAM

# Performance optimizations
--fast

# CRITICAL: Disable xformers - not compatible with Blackwell (sm_120)
# xformers only supports up to compute capability 9.0 (Ada/Hopper)
--disable-xformers

# Use PyTorch's native scaled dot product attention instead
--use-pytorch-cross-attention

# VRAM management - reserve 1GB for system overhead
--reserve-vram 1.0

# Use high VRAM mode (192GB allows full models in memory)
--highvram

# Preview generation
--preview-method auto

# With 192GB VRAM, multiple large models can stay loaded
